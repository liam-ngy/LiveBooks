# Processing links aerorecipe

```elixir
Mix.install([
  {:floki, "~> 0.34.3"},
  {:httpoison, "~> 2.1"},
  {:explorer, "~> 0.5.7"},
  {:kino_explorer, "~> 0.1.4"},
  {:vega_lite, "~> 0.1.7"},
  {:kino_vega_lite, "~> 0.1.9"},
  {:jason, "~> 1.4"}
])
```

## Reading from CSV and transform to list

Here we are fetching the csv data from my github repository

```elixir
require Explorer.DataFrame, as: DF
require Explorer.Series, as: Series

response =
  HTTPoison.get!(
    "https://raw.githubusercontent.com/liam-ngy/LiveBooks/main/data/aero_recipe_links.csv"
  )
```

To Parse the csv string we are loading the csv string into a DataFrame.

```elixir
base_link = "https://aeroprecipe.com"

links =
  DF.load_csv!(response.body, delimiter: "\t")
  |> DF.pull("links")
  |> Series.to_list()
  |> Enum.map(fn link -> base_link <> link end)
```

## Extract Data from single page

SingleRecipe represents a single side, it only cares about the happy path. Failure is not being handled

```elixir
defmodule SingleRecipe do
  # Construction
  def create_map(html, link \\ "") when is_bitstring(html) do
    parsed = Floki.parse_document!(html)

    %{
      title: title(parsed),
      description: description(parsed),
      category: category(parsed),
      recipe_details: recipe_details(parsed),
      coffee: coffee(parsed),
      water: water(parsed),
      steps: steps(parsed),
      votes: votes(parsed),
      link: link
    }
  end

  # Extraction
  defp title(html) do
    html
    |> Floki.find("h1")
    |> hd()
    |> Floki.text()
  end

  # -> String as HTML
  defp description(html) do
    html
    |> Floki.find("#recipeDescription")
    |> Floki.raw_html()
  end

  defp category(html) do
    case html |> Floki.find(".border-gray-500") do
      # Handle the case when the result is an empty list
      [] ->
        ""

      # Handle the case when at least one element is found
      [element | _rest] ->
        element
        |> Floki.text()
        |> String.trim_leading()
    end
  end

  defp recipe_overview(html, number) do
    html
    |> Floki.find(".bg-opacity-75 .mt-5")
    |> Enum.at(number)
    |> Floki.text(sep: ", ")
  end

  defp recipe_details(html) do
    html
    |> recipe_overview(1)
  end

  defp coffee(html) do
    html
    |> recipe_overview(2)
    |> String.replace("Coffee:, ", "")
  end

  defp water(html) do
    html
    |> recipe_overview(3)
    |> String.replace("Water:, ", "")
  end

  defp steps(html) do
    html
    |> Floki.find(".recipeSteps")
    |> Floki.text(sep: "\n")
  end

  defp votes(html) do
    result =
      html
      |> Floki.find(".border-pink-600")
      |> Floki.attribute("data-numvotes")
      |> Floki.text()

    result
  end
end
```

```elixir
defmodule Scraper do
  @chunk_size 30
  @timeout 1800_000
  @sleep_time 500

  # Starting point: Initiates the scraping process
  def scrape_links(links) do
    scrape_links(links, [], 0)
  end

  # Base case: No more links to process
  defp scrape_links([], accumulator, count) do
    IO.puts("All links processed. Total links processed: #{count}.")
    accumulator
  end

  # Recursive case: Processes a chunk of links
  defp scrape_links(links, accumulator, count) do
    {sliced_links, remaining_links} = Enum.split(links, @chunk_size)
    results = measure_time(fn -> scrape_chunk(sliced_links) end)
    new_count = count + length(results)

    :timer.sleep(@sleep_time)

    scrape_links(remaining_links, accumulator ++ results, new_count)
  end

  # Scrapes a chunk of links in parallel
  defp scrape_chunk(links) do
    tasks =
      Enum.map(links, fn link ->
        Task.async(fn -> fetch_recipe(link) end)
      end)

    Task.await_many(tasks, :infinity)
  end

  # Fetches a recipe from a given link
  defp fetch_recipe(link) do
    case HTTPoison.get(link, timeout: @timeout) do
      {:ok, response} ->
        html = response.body
        SingleRecipe.create_map(html, link)

      {:error, _reason} ->
        # Retry the request recursively in case of an error
        IO.puts("Error happened with #{link}")
        fetch_recipe(link)
    end
  end

  # Measures the time taken by a given function
  defp measure_time(fun) do
    start_time = :os.system_time(:millisecond)
    result = fun.()
    end_time = :os.system_time(:millisecond)
    elapsed_time = end_time - start_time
    elapsed_time_sec = elapsed_time / 1000.0
    IO.puts("Processed #{@chunk_size} #{elapsed_time_sec} seconds.")
    result
  end
end
```

## Scraper

```elixir
# results = Scraper.scrape_links(links)
```

## Create Dataframe and export as CSV

```elixir
# final_df =
#   DF.new(results)
#   |> DF.select([
#     "title",
#     "description",
#     "category",
#     "recipe_details",
#     "coffee",
#     "water",
#     "steps",
#     "votes",
#     "link"
#   ])
#   |> Explorer.DataFrame.mutate(votes: cast(votes, :integer))
```

```elixir
response =
  HTTPoison.get!(
    "https://raw.githubusercontent.com/liam-ngy/LiveBooks/main/data/aero_recipes.csv"
  )

df = DF.load_csv!(response.body)
```

Helper functions to extract recipe and water details

```elixir
# "99°C / 210°F, 200mL"
# |> String.split(", ")
# |>

extract_water_details = fn string ->
  separated_by_comma = String.split(string, ", ")

  amount_string = separated_by_comma |> List.last()

  temperature_list =
    separated_by_comma
    |> hd()
    |> String.split("/")

  [
    celcius: temperature_list |> hd(),
    fahrenheit: temperature_list |> List.last(),
    water_amount: amount_string
  ]
  |> Enum.map(fn {key, value} ->
    trimmed_string = String.trim(value)
    number = String.slice(trimmed_string, 0, String.length(trimmed_string) - 2)
    {key, number}
  end)
end

# |> hd()
# |> String.split("/")
# |> Enum.map(fn element ->
#   spaceless_element =  String.trim(element)
#   String.slice(spaceless_element, 0, String.length(spaceless_element) -2)
# end)
```

```elixir
extract_recipe_details = fn list ->
  %{
    method: Enum.at(list, 0),
    time: Enum.at(list, 1),
    filter_type: Enum.at(list, 2)
  }
end

# extract_water = fn list ->
#   %{

#   }
# end

# Split recipe details into single elements and create map
extracted_recipe_details_df =
  df
  |> DF.pull("recipe_details")
  |> Series.to_list()
  |> Enum.map(fn element ->
    String.split(element, ", ")
  end)
  |> Enum.map(fn element ->
    extract_recipe_details.(element)
  end)
  |> DF.new()

extracted_water_details_df =
  df
  |> DF.pull("water")
  |> Series.to_list()
  |> Enum.map(&extract_water_details.(&1))
  |> DF.new()

df = DF.concat_columns([df, extracted_recipe_details_df])
df = DF.concat_columns([df, extracted_water_details_df])

df =
  DF.put(
    df,
    :coffe_amount_in_g,
    Series.transform(df[:coffee], fn raw_coffee ->
      raw_coffee
      |> String.split(", ")
      |> List.first()
      # Remove g from string since it needs to be converted to float
      |> String.replace("g", "")
    end)
  )
  |> DF.mutate(coffe_amount_in_g: cast(coffe_amount_in_g, :float))
  |> DF.mutate(fahrenheit: cast(fahrenheit, :integer))
  |> DF.mutate(celcius: cast(celcius, :integer))
  |> DF.drop_nil()
  |> DF.select([
    :title,
    :description,
    :category,
    :steps,
    :votes,
    :link,
    :filter_type,
    :method,
    :time,
    :celcius,
    :fahrenheit,
    :water_amount,
    :coffe_amount_in_g
  ])

# |> > DF.select(["title", "description", "category", "recipe_details", "coffee", "water", "steps", "votes", "link"])

# coffee = "15g, Medium - Coarse, Kirinyaga, Kenya (as used in the 2018 WAC Finals)"
# |> String.split(", ")
# |> List.first()
```

```elixir
json_data =
  File.stream!("/Users/liam.ng/test.ndjson")
  |> Stream.map(&Jason.decode!/1)
  |> Enum.to_list()

json_data =
  %{"data" => json_data}
  |> Jason.encode!()
  |> Jason.Formatter.pretty_print()

# File.write!("aero_recipes.json", json_data)
```
